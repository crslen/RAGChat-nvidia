version: "3"
services:
  vllm-openai:
      deploy:
          resources:
              reservations:
                  devices:
                      - driver: nvidia
                        count: all
                        capabilities:
                            - gpu
      volumes:
          - ~/.cache/huggingface:/root/.cache/huggingface
          - ./models:/models
      environment:
          - HUGGING_FACE_HUB_TOKEN=<hugging_face_token>
      ports:
          - 8000:8000
      ipc: host
      image: vllm/vllm-openai:latest
      command: --model google/gemma-2b-it --enforce-eager --gpu-memory-utilization 0.8 --device cuda --download-dir /models
  
  postgres:
    build:
      # context: ./postgres
      dockerfile: postgres.Dockerfile
    ports:
      - "5432:5432"
    volumes:
      - ./data/:/var/lib/postgresql/data
      - ./postgres/vector_extension.sql:/docker-entrypoint-initdb.d/0-vector_extension.sql
      # - ./postgres/0-vector-extension.sh:/docker-entrypoint-initdb.d/0-vector-extension.sh

    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
      - POSTGRES_DB=vector
volumes:
  postgres_data: